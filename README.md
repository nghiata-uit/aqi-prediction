# ğŸŒ AQI Prediction System

Há»‡ thá»‘ng dá»± Ä‘oÃ¡n chá»‰ sá»‘ AQI (Air Quality Index) cho 24 giá» tiáº¿p theo sá»­ dá»¥ng Machine Learning.

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://www.python.org/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.2%2B-orange)](https://scikit-learn.org/)
[![XGBoost](https://img.shields.io/badge/XGBoost-1.7%2B-red)](https://xgboost.readthedocs.io/)

## ğŸ“Š Giá»›i thiá»‡u

Dá»± Ã¡n nÃ y xÃ¢y dá»±ng cÃ¡c models Machine Learning Ä‘á»ƒ dá»± Ä‘oÃ¡n chá»‰ sá»‘ cháº¥t lÆ°á»£ng khÃ´ng khÃ­ (AQI) dá»±a trÃªn dá»¯ liá»‡u lá»‹ch sá»­ vá» cÃ¡c cháº¥t Ã´ nhiá»…m nhÆ° CO, NO, NO2, O3, SO2, PM2.5, PM10, NH3.

### Features chÃ­nh:

- âœ… **3 Machine Learning models**: Random Forest, XGBoost, LSTM
- âœ… **Feature engineering tá»± Ä‘á»™ng** vá»›i lag vÃ  rolling statistics
- âœ… **Dá»± Ä‘oÃ¡n 24h trÆ°á»›c** vá»›i Ä‘á»™ chÃ­nh xÃ¡c cao
- âœ… **Jupyter Notebook** Ä‘á»ƒ phÃ¢n tÃ­ch vÃ  visualization
- âœ… **Visualizations Ä‘áº¹p máº¯t** vá»›i matplotlib vÃ  seaborn
- âœ… **Code production-ready** vá»›i logging, error handling, type hints

### Káº¿t quáº£ Performance:

| Model | MAE | RMSE | RÂ² Score |
|-------|-----|------|----------|
| Random Forest | 0.0032 | 0.0219 | 0.9994 |
| XGBoost | 0.1335 | 0.1782 | 0.9598 |

## ğŸ“ Cáº¥u trÃºc Project

```
aqi-prediction/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ .gitkeep
â”‚   â””â”€â”€ sample_data.csv          # Dá»¯ liá»‡u máº«u (588 rows, hourly data)
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ AQI_Prediction_Analysis.ipynb  # Jupyter notebook phÃ¢n tÃ­ch
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ .gitkeep
â”‚   â”œâ”€â”€ random_forest.pkl        # Random Forest model
â”‚   â”œâ”€â”€ xgboost.pkl              # XGBoost model
â”‚   â”œâ”€â”€ scaler.pkl               # StandardScaler
â”‚   â”œâ”€â”€ xgboost_global.pkl       # Global XGBoost vá»›i spatial features
â”‚   â”œâ”€â”€ feature_columns_global.pkl  # Feature names cho global model
â”‚   â””â”€â”€ spatial_scaler.pkl       # Spatial scaler cho lat/lon
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_preprocessing.py    # Xá»­ lÃ½ vÃ  lÃ m sáº¡ch dá»¯ liá»‡u
â”‚   â”œâ”€â”€ feature_engineering.py   # Táº¡o features (bao gá»“m spatial features)
â”‚   â”œâ”€â”€ model_training.py        # Train models
â”‚   â”œâ”€â”€ model_evaluation.py      # ÄÃ¡nh giÃ¡ models
â”‚   â””â”€â”€ prediction.py            # Dá»± Ä‘oÃ¡n 24h
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ train_global_model.py    # Train global spatial model
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ app.py                   # FastAPI application
â”‚   â””â”€â”€ dependencies.py          # Load vÃ  quáº£n lÃ½ artifacts
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ .gitkeep
â”‚   â”œâ”€â”€ rf_predictions.png       # Random Forest evaluation
â”‚   â”œâ”€â”€ xgb_predictions.png      # XGBoost evaluation
â”‚   â”œâ”€â”€ model_comparison.png     # So sÃ¡nh models
â”‚   â”œâ”€â”€ feature_importance.png   # Feature importance
â”‚   â””â”€â”€ 24h_forecast.png         # Dá»± Ä‘oÃ¡n 24h
â”œâ”€â”€ requirements.txt             # Dependencies
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â””â”€â”€ main.py                      # Script chÃ­nh
```

## ğŸš€ Installation

### 1. Clone repository

```bash
git clone https://github.com/nghiata-uit/aqi-prediction.git
cd aqi-prediction
```

### 2. Táº¡o virtual environment (khuyáº¿n nghá»‹)

```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# hoáº·c
venv\Scripts\activate  # Windows
```

### 3. CÃ i Ä‘áº·t dependencies

```bash
pip install -r requirements.txt
```

## ğŸ’» Usage

### Quick Start - Cháº¡y toÃ n bá»™ pipeline

```bash
python main.py
```

Pipeline sáº½ tá»± Ä‘á»™ng:
1. Load vÃ  preprocess dá»¯ liá»‡u
2. Táº¡o features (time, lag, rolling)
3. Split train/validation/test sets
4. Train Random Forest vÃ  XGBoost models
5. Evaluate vÃ  compare models
6. Generate 24-hour predictions
7. Save models vÃ  visualizations

### Output

Sau khi cháº¡y, báº¡n sáº½ cÃ³:

```
models/
â”œâ”€â”€ random_forest.pkl    # Trained Random Forest
â”œâ”€â”€ xgboost.pkl          # Trained XGBoost
â””â”€â”€ scaler.pkl           # Feature scaler

results/
â”œâ”€â”€ rf_predictions.png       # RF evaluation plots
â”œâ”€â”€ xgb_predictions.png      # XGBoost evaluation plots
â”œâ”€â”€ model_comparison.png     # Model comparison
â”œâ”€â”€ model_comparison.csv     # Metrics table
â”œâ”€â”€ feature_importance.png   # Top features
â”œâ”€â”€ feature_importance.csv   # All features
â”œâ”€â”€ 24h_forecast.png         # 24h prediction visualization
â””â”€â”€ 24h_predictions.csv      # 24h predictions data
```

### Sá»­ dá»¥ng trong code

```python
from src.data_preprocessing import preprocess_data
from src.feature_engineering import engineer_features
from src.prediction import predict_next_24h
import joblib

# Load data vÃ  preprocess
df = preprocess_data('data/sample_data.csv')

# Feature engineering
df_featured = engineer_features(df)

# Load trained model
model = joblib.load('models/xgboost.pkl')
scaler = joblib.load('models/scaler.pkl')

# Dá»± Ä‘oÃ¡n 24h
predictions = predict_next_24h(model, df_featured.tail(100), scaler, feature_cols)
print(predictions)
```

## ğŸ“ˆ Models

### 1. Random Forest Regressor

- **n_estimators**: 200
- **max_depth**: 15
- **Æ¯u Ä‘iá»ƒm**: Dá»… interpret, robust, feature importance
- **Káº¿t quáº£**: RÂ² = 0.9994

### 2. XGBoost Regressor

- **n_estimators**: 300
- **max_depth**: 7
- **learning_rate**: 0.05
- **Æ¯u Ä‘iá»ƒm**: Best performance, production-ready, handle missing values
- **Káº¿t quáº£**: RÂ² = 0.9598

### 3. LSTM (Optional)

- **Architecture**: LSTM(128) â†’ Dropout â†’ LSTM(64) â†’ Dense
- **Æ¯u Ä‘iá»ƒm**: Deep learning cho time series
- **Note**: Cáº§n cÃ i Ä‘áº·t TensorFlow

## ğŸ” Feature Engineering

Há»‡ thá»‘ng tá»± Ä‘á»™ng táº¡o 161 features tá»« dá»¯ liá»‡u gá»‘c:

### Time Features (9 features)
- hour, day_of_week, day, month, is_weekend
- Cyclical encoding: hour_sin, hour_cos, dow_sin, dow_cos

### Lag Features (48 features)
- GiÃ¡ trá»‹ cá»§a 8 pollutants á»Ÿ cÃ¡c thá»i Ä‘iá»ƒm trÆ°á»›c Ä‘Ã³
- Lags: 1h, 2h, 3h, 6h, 12h, 24h

### Rolling Statistics (96 features)
- Mean, Std, Min, Max cho 8 pollutants
- Windows: 6h, 12h, 24h

### Original Features (8 features)
- co, no, no2, o3, so2, pm2_5, pm10, nh3

## ğŸ”® 24h Prediction Example

```python
from src.prediction import load_model_and_predict

predictions = load_model_and_predict(
    model_path='models/xgboost.pkl',
    scaler_path='models/scaler.pkl',
    data_path='data/sample_data.csv'
)

print(predictions.head())
```

Output:
```
 hour           timestamp  predicted_aqi
    1 2020-11-25 12:00:00           4.65
    2 2020-11-25 13:00:00           4.65
    3 2020-11-25 14:00:00           4.65
    4 2020-11-25 15:00:00           4.65
    5 2020-11-25 16:00:00           4.65
```

## ğŸ“Š Data

### Sample Data

Dá»¯ liá»‡u máº«u bao gá»“m:
- **Thá»i gian**: 2020-11-01 00:00:00 Ä‘áº¿n 2020-11-25 11:00:00 (588 hours)
- **Location**: lon=10.804, lat=106.7075 (khu vá»±c TP.HCM)
- **Target**: AQI (2-5: Good to Poor)
- **Features**: 8 pollutants

### Pollutants

| Pollutant | Range | Unit | Description |
|-----------|-------|------|-------------|
| CO | 400-1200 | Î¼g/mÂ³ | Carbon Monoxide |
| NO | 1-25 | Î¼g/mÂ³ | Nitrogen Monoxide |
| NO2 | 10-35 | Î¼g/mÂ³ | Nitrogen Dioxide |
| O3 | 1-100 | Î¼g/mÂ³ | Ozone |
| SO2 | 15-40 | Î¼g/mÂ³ | Sulfur Dioxide |
| PM2.5 | 15-50 | Î¼g/mÂ³ | Fine Particulate Matter |
| PM10 | 30-80 | Î¼g/mÂ³ | Coarse Particulate Matter |
| NH3 | 3-15 | Î¼g/mÂ³ | Ammonia |

### AQI Levels

| AQI | Level | Description |
|-----|-------|-------------|
| 1-2 | Good | Cháº¥t lÆ°á»£ng khÃ´ng khÃ­ tá»‘t |
| 2-3 | Fair | Cháº¥t lÆ°á»£ng khÃ´ng khÃ­ trung bÃ¬nh |
| 3-4 | Moderate | Cháº¥t lÆ°á»£ng khÃ´ng khÃ­ kÃ©m |
| 4-5 | Poor | Cháº¥t lÆ°á»£ng khÃ´ng khÃ­ xáº¥u |

## ğŸ› ï¸ Development

### ThÃªm model má»›i

1. Implement trong `src/model_training.py`:

```python
def train_new_model(self, X_train, y_train, X_val, y_val):
    model = YourModel(...)
    model.fit(X_train, y_train)
    return model
```

2. ThÃªm vÃ o pipeline trong `main.py`
3. Update evaluation vÃ  comparison

### ThÃªm features má»›i

Implement trong `src/feature_engineering.py`:

```python
def create_custom_features(df: pd.DataFrame) -> pd.DataFrame:
    # Your feature engineering logic
    return df
```

### Testing

```bash
# Test data preprocessing
python -c "from src.data_preprocessing import preprocess_data; df = preprocess_data('data/sample_data.csv'); print(df.shape)"

# Test feature engineering
python -c "from src.feature_engineering import engineer_features; from src.data_preprocessing import preprocess_data; df = preprocess_data('data/sample_data.csv'); df_feat = engineer_features(df); print(df_feat.shape)"
```

## ğŸ“ Notes

### Best Practices

- âœ… Time series dÃ¹ng **time-based split** (khÃ´ng shuffle)
- âœ… Lag features lÃ  **quan trá»ng nháº¥t** cho time series
- âœ… XGBoost thÆ°á»ng cho **káº¿t quáº£ tá»‘t nháº¥t**
- âœ… LSTM cáº§n **sequence preparation** (3D input)
- âœ… DÃ¹ng **StandardScaler** cho numerical features
- âœ… Save models vÃ  scaler Ä‘á»ƒ **reuse**

### Common Issues

**Q: LSTM khÃ´ng train Ä‘Æ°á»£c?**
A: Cáº§n cÃ i Ä‘áº·t TensorFlow: `pip install tensorflow>=2.10.0`

**Q: Káº¿t quáº£ khÃ¡c nhau má»—i láº§n cháº¡y?**
A: Set random seed trong code (Ä‘Ã£ implement)

**Q: Muá»‘n dÃ¹ng dá»¯ liá»‡u thá»±c?**
A: Replace `data/sample_data.csv` vá»›i data cá»§a báº¡n (cÃ¹ng format)

## ğŸŒ Global Spatial Model (Method A)

### Giá»›i thiá»‡u

Project hiá»‡n Ä‘Ã£ implement **Method A**: má»™t global XGBoost model vá»›i spatial features (lat, lon). Model nÃ y cÃ³ thá»ƒ dá»± Ä‘oÃ¡n AQI cho báº¥t ká»³ vá»‹ trÃ­ Ä‘á»‹a lÃ½ nÃ o, khÃ´ng chá»‰ giá»›i háº¡n á»Ÿ má»™t Ä‘á»‹a Ä‘iá»ƒm cá»¥ thá»ƒ.

### Training Global Model

Äá»ƒ train global model vá»›i spatial features:

```bash
python scripts/train_global_model.py
```

Script nÃ y sáº½:
- Load dá»¯ liá»‡u tá»« `data/sample_data.csv`
- Táº¡o time features, lag features, rolling features vÃ  **spatial features** (lat, lon chuáº©n hÃ³a)
- Split dá»¯ liá»‡u theo thá»i gian (70% train, 30% test)
- Train XGBoost model
- Save artifacts vÃ o `models/`:
  - `xgboost_global.pkl` - Model Ä‘Ã£ train
  - `feature_columns_global.pkl` - Danh sÃ¡ch feature names
  - `spatial_scaler.pkl` - StandardScaler cho lat/lon

### Model Artifacts

Sau khi train, cÃ¡c artifacts Ä‘Æ°á»£c lÆ°u trong `models/`:

```
models/
â”œâ”€â”€ xgboost_global.pkl           # Trained XGBoost model
â”œâ”€â”€ feature_columns_global.pkl   # Feature names (163 features)
â””â”€â”€ spatial_scaler.pkl           # Spatial scaler cho lat/lon
```

### Sá»­ dá»¥ng API

API cung cáº¥p endpoints Ä‘á»ƒ predict AQI dá»±a trÃªn pollutants vÃ  vá»‹ trÃ­ Ä‘á»‹a lÃ½.

#### Khá»Ÿi Ä‘á»™ng API:

```bash
python -m uvicorn api.app:app --host 0.0.0.0 --port 8000
```

Hoáº·c:

```bash
python api/app.py
```

API sáº½ tá»± Ä‘á»™ng load cÃ¡c artifacts khi startup.

#### API Endpoints:

- **GET /** - Root endpoint vá»›i thÃ´ng tin API
- **GET /health** - Health check, kiá»ƒm tra artifacts Ä‘Ã£ load
- **GET /model-info** - ThÃ´ng tin chi tiáº¿t vá» model vÃ  features
- **POST /predict** - Predict AQI tá»« input data

#### Example Request:

```bash
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "lat": 106.7075,
    "lon": 10.804,
    "co": 704.51,
    "no": 8.31,
    "no2": 21.89,
    "o3": 63.35,
    "so2": 21.33,
    "pm2_5": 25.13,
    "pm10": 63.95,
    "nh3": 9.5
  }'
```

#### Example Response:

```json
{
  "predicted_aqi": 3.05,
  "lat_scaled": 0.0,
  "lon_scaled": 0.0,
  "model_name": "xgboost_global"
}
```

### Kiáº¿n trÃºc

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Input Data    â”‚
â”‚ (lat, lon, CO,  â”‚
â”‚  NO, NO2, ...)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Spatial Scaler  â”‚
â”‚ (lat/lon â†’ std) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Feature Engineer â”‚
â”‚ (time, lag,     â”‚
â”‚  rolling feat.) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ XGBoost Global  â”‚
â”‚     Model       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Predicted AQI  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Features

Global model sá»­ dá»¥ng **163 features**, bao gá»“m:
- **2 Spatial features**: lat_scaled, lon_scaled
- **9 Time features**: hour, day_of_week, day, month, is_weekend, cyclical encodings
- **48 Lag features**: 8 pollutants Ã— 6 lags (1h, 2h, 3h, 6h, 12h, 24h)
- **96 Rolling features**: 8 pollutants Ã— 3 windows (6h, 12h, 24h) Ã— 4 stats (mean, std, min, max)
- **8 Original features**: co, no, no2, o3, so2, pm2_5, pm10, nh3

## ğŸ¯ Future Improvements

- [ ] Add more models (LightGBM, CatBoost)
- [ ] Implement hyperparameter tuning
- [ ] Add real-time prediction API
- [ ] Deploy with Docker
- [ ] Add unit tests
- [ ] Integrate with real AQI APIs
- [ ] Add data validation vá»›i Great Expectations
- [ ] Implement MLOps pipeline

## ğŸ“š References

- [WHO Air Quality Guidelines](https://www.who.int/news-room/fact-sheets/detail/ambient-(outdoor)-air-quality-and-health)
- [EPA AQI Basics](https://www.airnow.gov/aqi/aqi-basics/)
- [XGBoost Documentation](https://xgboost.readthedocs.io/)
- [Scikit-learn Time Series](https://scikit-learn.org/stable/auto_examples/applications/plot_cyclical_feature_engineering.html)

## ğŸ“ License

MIT License - see [LICENSE](LICENSE) file for details

## ğŸ‘¨â€ğŸ’» Author

**nghiata-uit**

- GitHub: [@nghiata-uit](https://github.com/nghiata-uit)
- Repository: [aqi-prediction](https://github.com/nghiata-uit/aqi-prediction)

---

â­ Náº¿u project há»¯u Ã­ch, hÃ£y star repository nÃ y!
