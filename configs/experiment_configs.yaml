# Mamba-SEUNet Experiment Configuration

# Model Configuration
model:
  name: mamba_seunet
  in_channels: 1
  out_channels: 1
  num_mamba_blocks: 6  # Default: 6 TS-Mamba blocks
  hidden_dim: 256
  state_dim: 16
  conv_kernel: 4
  expand_factor: 2
  dropout: 0.1
  use_residual: true
  use_layer_norm: true

# Training Configuration
training:
  batch_size: 16
  epochs: 100
  num_workers: 4
  pin_memory: true
  
  # Optimizer
  optimizer:
    type: adam
    learning_rate: 0.0001
    betas: [0.9, 0.999]
    weight_decay: 0.0001
    eps: 1.0e-8
  
  # Learning Rate Scheduler
  scheduler:
    type: cosine_annealing
    T_max: 100
    eta_min: 1.0e-6
    warmup_epochs: 5
    warmup_start_lr: 1.0e-6
  
  # Gradient
  gradient_clip: 5.0
  mixed_precision: true
  
  # Checkpointing
  save_every_n_epochs: 5
  keep_n_checkpoints: 3
  checkpoint_dir: checkpoints
  
  # Validation
  validate_every_n_epochs: 1
  
  # Early Stopping
  early_stopping:
    enabled: true
    patience: 15
    min_delta: 0.001

# Loss Configuration
loss:
  type: combined
  losses:
    l1:
      weight: 1.0
      reduction: mean
    l2:
      weight: 0.5
      reduction: mean
    si_snr:
      weight: 0.1
      reduction: mean
    perceptual:
      weight: 0.0  # Disable by default
      reduction: mean

# Data Configuration
data:
  # Audio Processing
  sample_rate: 16000
  segment_length: 4.0  # seconds
  
  # STFT Parameters
  n_fft: 512
  hop_length: 160
  win_length: 512
  window: hann
  center: true
  normalized: false
  onesided: true
  
  # Normalization
  normalize: true
  norm_type: instance  # instance, batch, or none
  
  # Dataset Paths
  vctk_demand:
    clean_train: data/VCTK-DEMAND/clean_trainset_28spk_wav
    noisy_train: data/VCTK-DEMAND/noisy_trainset_28spk_wav
    clean_test: data/VCTK-DEMAND/clean_testset_wav
    noisy_test: data/VCTK-DEMAND/noisy_testset_wav
  
  voicebank_demand:
    clean_train: data/VoiceBank-DEMAND/clean_trainset_wav
    noisy_train: data/VoiceBank-DEMAND/noisy_trainset_wav
    clean_test: data/VoiceBank-DEMAND/clean_testset_wav
    noisy_test: data/VoiceBank-DEMAND/noisy_testset_wav
  
  # Data Split
  train_split: 0.9
  val_split: 0.1
  
  # Noise Mixing (for on-the-fly mixing)
  noise_types:
    - babble
    - cafe
    - car
    - living
    - office
    - psquare
    - restaurant
    - station
    - traffic
    - washing
  snr_range: [-5, 20]  # dB

# Augmentation Configuration
augmentation:
  enabled: true
  train_only: true
  
  random_noise:
    prob: 0.5
    snr_range: [-5, 20]
  
  time_stretch:
    prob: 0.3
    rate_range: [0.9, 1.1]
  
  pitch_shift:
    prob: 0.3
    n_steps_range: [-2, 2]
  
  spec_augment:
    prob: 0.5
    freq_mask_param: 15
    time_mask_param: 25
    n_freq_masks: 2
    n_time_masks: 2

# Evaluation Configuration
evaluation:
  batch_size: 8
  num_workers: 2
  
  # Metrics
  metrics:
    - pesq
    - stoi
    - si_sdr
    - dnsmos
  
  # Save Options
  save_enhanced_audio: true
  save_spectrograms: true
  save_waveforms: true
  output_dir: results/evaluation
  
  # Comparison
  plot_comparisons: true
  n_samples_to_plot: 10

# Baseline Models Configuration
baselines:
  cnn_unet:
    channels: [64, 128, 256, 512]
    kernel_size: 3
    stride: 2
    padding: 1
  
  transformer_unet:
    channels: [64, 128, 256, 512]
    num_transformer_layers: 4
    num_heads: 8
    dim_feedforward: 1024
    dropout: 0.1
  
  conformer_unet:
    channels: [64, 128, 256, 512]
    num_conformer_blocks: 4
    num_heads: 8
    dim_feedforward: 1024
    conv_kernel_size: 31
    dropout: 0.1

# Ablation Study Configuration
ablation:
  num_mamba_blocks_range: [2, 4, 6, 8, 10]
  measure_flops: true
  measure_params: true
  measure_inference_time: true
  
# Perceptual Contrast Stretching Configuration
contrast_stretching:
  enabled: false
  alpha: 0.3  # Stretching factor
  apply_to_magnitude: true
  
# Logging Configuration
logging:
  use_tensorboard: true
  tensorboard_dir: runs
  log_every_n_steps: 100
  log_learning_rate: true
  log_gradients: false
  log_weights: false
  
  # Wandb (optional)
  use_wandb: false
  wandb_project: mamba-seunet
  wandb_entity: null

# System Configuration
system:
  device: cuda  # cuda or cpu
  gpu_ids: [0]  # List of GPU IDs to use
  use_data_parallel: false
  use_distributed: false
  seed: 42
  deterministic: false
  benchmark: true

# Experiment-Specific Overrides
experiments:
  table_1_main_comparison:
    models: [cnn_unet, transformer_unet, conformer_unet, mamba_seunet]
    dataset: vctk_demand
    epochs: 100
    
  table_4_ablation_study:
    model: mamba_seunet
    num_mamba_blocks_range: [2, 4, 6, 8, 10]
    dataset: vctk_demand
    epochs: 100
    
  contrast_stretching_exp:
    model: mamba_seunet
    dataset: vctk_demand
    use_pretrained: true
    checkpoint: checkpoints/mamba_seunet_best.pt
    alpha_range: [0.1, 0.2, 0.3, 0.4, 0.5]
