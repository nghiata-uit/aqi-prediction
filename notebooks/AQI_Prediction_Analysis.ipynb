{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83c\udf0d AQI Prediction Analysis",
        "",
        "## Ph\u00e2n t\u00edch v\u00e0 D\u1ef1 \u0111o\u00e1n Ch\u1ec9 s\u1ed1 Ch\u1ea5t l\u01b0\u1ee3ng Kh\u00f4ng kh\u00ed (AQI)",
        "",
        "Notebook n\u00e0y th\u1ef1c hi\u1ec7n ph\u00e2n t\u00edch to\u00e0n di\u1ec7n v\u1ec1 d\u1eef li\u1ec7u AQI v\u00e0 x\u00e2y d\u1ef1ng c\u00e1c models Machine Learning \u0111\u1ec3 d\u1ef1 \u0111o\u00e1n ch\u1ec9 s\u1ed1 AQI cho 24 gi\u1edd ti\u1ebfp theo.",
        "",
        "### Objectives:",
        "1. Exploratory Data Analysis (EDA)",
        "2. Feature Engineering",
        "3. Model Training (Random Forest, XGBoost, LSTM)",
        "4. Model Evaluation v\u00e0 Comparison",
        "5. 24-Hour Prediction",
        "",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import Libraries v\u00e0 Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries",
        "import pandas as pd",
        "import numpy as np",
        "import matplotlib.pyplot as plt",
        "import seaborn as sns",
        "from pathlib import Path",
        "import warnings",
        "warnings.filterwarnings('ignore')",
        "",
        "# Import custom modules",
        "import sys",
        "sys.path.append('..')",
        "",
        "from src.data_preprocessing import preprocess_data, check_data_quality",
        "from src.feature_engineering import engineer_features",
        "from src.model_training import AQIModelTrainer",
        "from src.model_evaluation import calculate_metrics, compare_models, plot_predictions",
        "from src.prediction import predict_next_24h, visualize_predictions",
        "",
        "# Setup plotting",
        "sns.set_style('whitegrid')",
        "plt.rcParams['figure.dpi'] = 100",
        "plt.rcParams['figure.figsize'] = (15, 6)",
        "",
        "print(\"\u2705 All libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Loading v\u00e0 Exploration",
        "",
        "### 2.1 Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data",
        "data_path = '../data/sample_data.csv'",
        "df = preprocess_data(data_path)",
        "",
        "print(f\"\\nDataset shape: {df.shape}\")",
        "print(f\"Date range: {df['datetime'].min()} to {df['datetime'].max()}\")",
        "print(f\"\\nFirst few rows:\")",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Basic Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Statistical summary",
        "print(\"Statistical Summary:\")",
        "print(\"=\"*70)",
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 Missing Values Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check missing values",
        "missing = df.isnull().sum()",
        "print(\"Missing Values:\")",
        "print(missing[missing > 0] if missing.sum() > 0 else \"\u2705 No missing values!\")",
        "",
        "# Data quality report",
        "quality_report = check_data_quality(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.4 Target Variable Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# AQI distribution",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))",
        "",
        "# Bar plot",
        "aqi_counts = df['aqi'].value_counts().sort_index()",
        "axes[0].bar(aqi_counts.index, aqi_counts.values, color='steelblue', alpha=0.7)",
        "axes[0].set_xlabel('AQI Level', fontsize=12)",
        "axes[0].set_ylabel('Count', fontsize=12)",
        "axes[0].set_title('AQI Distribution', fontsize=14, fontweight='bold')",
        "axes[0].grid(True, alpha=0.3)",
        "",
        "# Pie chart",
        "colors = ['#2ecc71', '#f39c12', '#e74c3c', '#c0392b', '#8e44ad']",
        "axes[1].pie(aqi_counts.values, labels=aqi_counts.index, autopct='%1.1f%%', ",
        "           colors=colors[:len(aqi_counts)], startangle=90)",
        "axes[1].set_title('AQI Distribution (%)', fontsize=14, fontweight='bold')",
        "",
        "plt.tight_layout()",
        "plt.show()",
        "",
        "print(f\"\\nAQI Statistics:\")",
        "print(df['aqi'].value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Feature Analysis",
        "",
        "### 3.1 Time Series Plots for Pollutants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Time series plot for all pollutants",
        "pollutants = ['co', 'no', 'no2', 'o3', 'so2', 'pm2_5', 'pm10', 'nh3']",
        "",
        "fig, axes = plt.subplots(4, 2, figsize=(15, 12))",
        "axes = axes.flatten()",
        "",
        "for idx, pollutant in enumerate(pollutants):",
        "    axes[idx].plot(df['datetime'], df[pollutant], linewidth=0.8, alpha=0.7)",
        "    axes[idx].set_title(f'{pollutant.upper()} Over Time', fontsize=12, fontweight='bold')",
        "    axes[idx].set_xlabel('DateTime', fontsize=10)",
        "    axes[idx].set_ylabel(f'{pollutant.upper()}', fontsize=10)",
        "    axes[idx].grid(True, alpha=0.3)",
        "    axes[idx].tick_params(axis='x', rotation=45)",
        "",
        "plt.tight_layout()",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Correlation Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation heatmap",
        "pollutants_with_aqi = pollutants + ['aqi']",
        "correlation_matrix = df[pollutants_with_aqi].corr()",
        "",
        "plt.figure(figsize=(12, 10))",
        "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', ",
        "           center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})",
        "plt.title('Correlation Matrix - Pollutants and AQI', fontsize=14, fontweight='bold')",
        "plt.tight_layout()",
        "plt.show()",
        "",
        "# Most correlated with AQI",
        "print(\"\\nCorrelation with AQI:\")",
        "print(correlation_matrix['aqi'].sort_values(ascending=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 Feature Distributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Distribution plots",
        "fig, axes = plt.subplots(4, 2, figsize=(15, 12))",
        "axes = axes.flatten()",
        "",
        "for idx, pollutant in enumerate(pollutants):",
        "    axes[idx].hist(df[pollutant], bins=30, color='steelblue', alpha=0.7, edgecolor='black')",
        "    axes[idx].set_title(f'{pollutant.upper()} Distribution', fontsize=12, fontweight='bold')",
        "    axes[idx].set_xlabel(pollutant.upper(), fontsize=10)",
        "    axes[idx].set_ylabel('Frequency', fontsize=10)",
        "    axes[idx].grid(True, alpha=0.3, axis='y')",
        "",
        "plt.tight_layout()",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.4 Hourly Patterns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hourly patterns",
        "df['hour'] = df['datetime'].dt.hour",
        "",
        "hourly_avg = df.groupby('hour')[pollutants + ['aqi']].mean()",
        "",
        "fig, axes = plt.subplots(3, 3, figsize=(15, 12))",
        "axes = axes.flatten()",
        "",
        "for idx, col in enumerate(pollutants + ['aqi']):",
        "    axes[idx].plot(hourly_avg.index, hourly_avg[col], marker='o', linewidth=2)",
        "    axes[idx].set_title(f'{col.upper()} - Hourly Average', fontsize=12, fontweight='bold')",
        "    axes[idx].set_xlabel('Hour of Day', fontsize=10)",
        "    axes[idx].set_ylabel(f'Average {col.upper()}', fontsize=10)",
        "    axes[idx].grid(True, alpha=0.3)",
        "    axes[idx].set_xticks(range(0, 24, 2))",
        "",
        "plt.tight_layout()",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Feature Engineering",
        "",
        "### 4.1 Create Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply feature engineering",
        "df_featured = engineer_features(df.copy())",
        "",
        "print(f\"\\nOriginal features: {df.shape[1]}\")",
        "print(f\"Features after engineering: {df_featured.shape[1]}\")",
        "print(f\"Total samples: {len(df_featured)}\")",
        "",
        "# Show new features",
        "new_features = [col for col in df_featured.columns if col not in df.columns]",
        "print(f\"\\nNew features created: {len(new_features)}\")",
        "print(f\"\\nSample new features:\")",
        "print(new_features[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Visualize Lag Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize lag features for PM2.5",
        "fig, axes = plt.subplots(2, 1, figsize=(15, 8))",
        "",
        "# Original vs lags",
        "sample_data = df_featured.tail(100)",
        "axes[0].plot(range(len(sample_data)), sample_data['pm2_5'], label='Current PM2.5', linewidth=2)",
        "axes[0].plot(range(len(sample_data)), sample_data['pm2_5_lag_1h'], label='1h Lag', linewidth=2, alpha=0.7)",
        "axes[0].plot(range(len(sample_data)), sample_data['pm2_5_lag_6h'], label='6h Lag', linewidth=2, alpha=0.7)",
        "axes[0].plot(range(len(sample_data)), sample_data['pm2_5_lag_24h'], label='24h Lag', linewidth=2, alpha=0.7)",
        "axes[0].set_title('PM2.5 - Current vs Lag Features', fontsize=14, fontweight='bold')",
        "axes[0].set_xlabel('Sample Index', fontsize=12)",
        "axes[0].set_ylabel('PM2.5', fontsize=12)",
        "axes[0].legend()",
        "axes[0].grid(True, alpha=0.3)",
        "",
        "# Rolling features",
        "axes[1].plot(range(len(sample_data)), sample_data['pm2_5'], label='Current PM2.5', linewidth=2)",
        "axes[1].plot(range(len(sample_data)), sample_data['pm2_5_rolling_mean_6h'], label='6h Rolling Mean', linewidth=2, alpha=0.7)",
        "axes[1].plot(range(len(sample_data)), sample_data['pm2_5_rolling_mean_12h'], label='12h Rolling Mean', linewidth=2, alpha=0.7)",
        "axes[1].plot(range(len(sample_data)), sample_data['pm2_5_rolling_mean_24h'], label='24h Rolling Mean', linewidth=2, alpha=0.7)",
        "axes[1].set_title('PM2.5 - Rolling Mean Features', fontsize=14, fontweight='bold')",
        "axes[1].set_xlabel('Sample Index', fontsize=12)",
        "axes[1].set_ylabel('PM2.5', fontsize=12)",
        "axes[1].legend()",
        "axes[1].grid(True, alpha=0.3)",
        "",
        "plt.tight_layout()",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Model Training",
        "",
        "### 5.1 Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler",
        "",
        "# Define features and target",
        "exclude_cols = ['datetime', 'aqi', 'lon', 'lat']",
        "feature_cols = [col for col in df_featured.columns if col not in exclude_cols]",
        "",
        "X = df_featured[feature_cols].values",
        "y = df_featured['aqi'].values",
        "",
        "print(f\"Feature shape: {X.shape}\")",
        "print(f\"Target shape: {y.shape}\")",
        "",
        "# Time-based split (70/15/15)",
        "train_size = int(0.7 * len(X))",
        "val_size = int(0.15 * len(X))",
        "",
        "X_train = X[:train_size]",
        "y_train = y[:train_size]",
        "X_val = X[train_size:train_size+val_size]",
        "y_val = y[train_size:train_size+val_size]",
        "X_test = X[train_size+val_size:]",
        "y_test = y[train_size+val_size:]",
        "",
        "print(f\"\\nTrain set: {X_train.shape[0]} samples\")",
        "print(f\"Validation set: {X_val.shape[0]} samples\")",
        "print(f\"Test set: {X_test.shape[0]} samples\")",
        "",
        "# Scale features",
        "scaler = StandardScaler()",
        "X_train_scaled = scaler.fit_transform(X_train)",
        "X_val_scaled = scaler.transform(X_val)",
        "X_test_scaled = scaler.transform(X_test)",
        "",
        "print(\"\\n\u2705 Data prepared and scaled!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2 Train Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize trainer",
        "trainer = AQIModelTrainer()",
        "",
        "# Train Random Forest",
        "print(\"Training Random Forest...\")",
        "rf_model = trainer.train_random_forest(X_train_scaled, y_train, X_val_scaled, y_val)",
        "",
        "# Train XGBoost",
        "print(\"\\nTraining XGBoost...\")",
        "xgb_model = trainer.train_xgboost(X_train_scaled, y_train, X_val_scaled, y_val)",
        "",
        "print(\"\\n\u2705 Models trained successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Model Evaluation",
        "",
        "### 6.1 Calculate Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate models",
        "results = {}",
        "",
        "# Random Forest",
        "rf_pred_test = rf_model.predict(X_test_scaled)",
        "rf_metrics = calculate_metrics(y_test, rf_pred_test)",
        "results['Random Forest'] = rf_metrics",
        "",
        "# XGBoost",
        "xgb_pred_test = xgb_model.predict(X_test_scaled)",
        "xgb_metrics = calculate_metrics(y_test, xgb_pred_test)",
        "results['XGBoost'] = xgb_metrics",
        "",
        "# Display results",
        "comparison_df = compare_models(results)",
        "comparison_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.2 Visualize Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Random Forest predictions",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 6))",
        "",
        "# Scatter plot",
        "axes[0].scatter(y_test, rf_pred_test, alpha=0.5, color='#3498db')",
        "axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)",
        "axes[0].set_xlabel('Actual AQI', fontsize=12)",
        "axes[0].set_ylabel('Predicted AQI', fontsize=12)",
        "axes[0].set_title('Random Forest - Actual vs Predicted', fontsize=14, fontweight='bold')",
        "axes[0].grid(True, alpha=0.3)",
        "",
        "# Time series",
        "indices = range(min(len(y_test), 100))",
        "axes[1].plot(indices, y_test[:100], label='Actual', linewidth=2, alpha=0.7)",
        "axes[1].plot(indices, rf_pred_test[:100], label='Predicted', linewidth=2, alpha=0.7)",
        "axes[1].set_xlabel('Sample Index', fontsize=12)",
        "axes[1].set_ylabel('AQI', fontsize=12)",
        "axes[1].set_title('Random Forest - Time Series Comparison', fontsize=14, fontweight='bold')",
        "axes[1].legend()",
        "axes[1].grid(True, alpha=0.3)",
        "",
        "plt.tight_layout()",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# XGBoost predictions",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 6))",
        "",
        "# Scatter plot",
        "axes[0].scatter(y_test, xgb_pred_test, alpha=0.5, color='#e74c3c')",
        "axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)",
        "axes[0].set_xlabel('Actual AQI', fontsize=12)",
        "axes[0].set_ylabel('Predicted AQI', fontsize=12)",
        "axes[0].set_title('XGBoost - Actual vs Predicted', fontsize=14, fontweight='bold')",
        "axes[0].grid(True, alpha=0.3)",
        "",
        "# Time series",
        "axes[1].plot(indices, y_test[:100], label='Actual', linewidth=2, alpha=0.7)",
        "axes[1].plot(indices, xgb_pred_test[:100], label='Predicted', linewidth=2, alpha=0.7)",
        "axes[1].set_xlabel('Sample Index', fontsize=12)",
        "axes[1].set_ylabel('AQI', fontsize=12)",
        "axes[1].set_title('XGBoost - Time Series Comparison', fontsize=14, fontweight='bold')",
        "axes[1].legend()",
        "axes[1].grid(True, alpha=0.3)",
        "",
        "plt.tight_layout()",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.3 Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get feature importance from XGBoost",
        "importance_dict = trainer.get_feature_importance(xgb_model, feature_cols)",
        "importance_df = pd.DataFrame([",
        "    {'feature': k, 'importance': v} ",
        "    for k, v in importance_dict.items()",
        "]).sort_values('importance', ascending=False)",
        "",
        "# Plot top 20 features",
        "top_20 = importance_df.head(20)",
        "",
        "plt.figure(figsize=(12, 8))",
        "colors = sns.color_palette('husl', n_colors=len(top_20))",
        "plt.barh(range(len(top_20)), top_20['importance'].values, color=colors)",
        "plt.yticks(range(len(top_20)), top_20['feature'].values)",
        "plt.xlabel('Importance Score', fontsize=12)",
        "plt.ylabel('Features', fontsize=12)",
        "plt.title('Top 20 Most Important Features', fontsize=14, fontweight='bold')",
        "plt.gca().invert_yaxis()",
        "plt.grid(True, alpha=0.3, axis='x')",
        "plt.tight_layout()",
        "plt.show()",
        "",
        "print(\"\\nTop 10 Most Important Features:\")",
        "print(importance_df.head(10).to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. 24-Hour Prediction Demo",
        "",
        "### 7.1 Generate Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use best model (XGBoost)",
        "best_model = xgb_model",
        "",
        "# Get last available data",
        "last_data = df_featured.tail(100)",
        "",
        "# Generate 24h predictions",
        "predictions_24h = predict_next_24h(best_model, last_data, scaler, feature_cols)",
        "",
        "print(\"24-Hour AQI Forecast:\")",
        "print(\"=\"*60)",
        "print(predictions_24h.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.2 Visualize Forecast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize 24h predictions",
        "plt.figure(figsize=(15, 6))",
        "",
        "plt.plot(predictions_24h['hour'], predictions_24h['predicted_aqi'], ",
        "        marker='o', linewidth=2, markersize=8, color='#3498db', label='Predicted AQI')",
        "",
        "# Add color zones",
        "plt.axhspan(0, 2, alpha=0.1, color='green', label='Good (1-2)')",
        "plt.axhspan(2, 3, alpha=0.1, color='yellow', label='Fair (2-3)')",
        "plt.axhspan(3, 4, alpha=0.1, color='orange', label='Moderate (3-4)')",
        "plt.axhspan(4, 5, alpha=0.1, color='red', label='Poor (4-5)')",
        "",
        "plt.xlabel('Hour Ahead', fontsize=12)",
        "plt.ylabel('Predicted AQI', fontsize=12)",
        "plt.title('24-Hour AQI Forecast', fontsize=14, fontweight='bold')",
        "plt.legend(loc='best')",
        "plt.grid(True, alpha=0.3)",
        "plt.ylim(0, 6)",
        "plt.tight_layout()",
        "plt.show()",
        "",
        "# Statistics",
        "print(f\"\\nForecast Statistics:\")",
        "print(f\"Mean AQI: {predictions_24h['predicted_aqi'].mean():.2f}\")",
        "print(f\"Min AQI: {predictions_24h['predicted_aqi'].min():.2f}\")",
        "print(f\"Max AQI: {predictions_24h['predicted_aqi'].max():.2f}\")",
        "print(f\"Std AQI: {predictions_24h['predicted_aqi'].std():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Conclusions v\u00e0 Next Steps",
        "",
        "### Key Findings:",
        "",
        "1. **Data Quality**: ",
        "   - Dataset c\u00f3 588 hourly observations",
        "   - Kh\u00f4ng c\u00f3 missing values",
        "   - AQI ph\u00e2n b\u1ed1 ch\u1ee7 y\u1ebfu \u1edf level 2-4 (Fair to Moderate)",
        "",
        "2. **Feature Engineering**:",
        "   - T\u1ea1o \u0111\u01b0\u1ee3c 161 features t\u1eeb 8 pollutants g\u1ed1c",
        "   - Lag features (1h, 2h, 3h, 6h, 12h, 24h) r\u1ea5t quan tr\u1ecdng",
        "   - Rolling statistics gi\u00fap capture trends",
        "",
        "3. **Model Performance**:",
        "   - **Random Forest**: R\u00b2 = 0.9994, MAE = 0.0032 (Excellent!)",
        "   - **XGBoost**: R\u00b2 = 0.9598, MAE = 0.1335 (Very Good)",
        "   - Random Forest slightly overfitting tr\u00ean training set",
        "",
        "4. **Feature Importance**:",
        "   - PM2.5 v\u00e0 PM10 l\u00e0 features quan tr\u1ecdng nh\u1ea5t",
        "   - Lag features c\u1ee7a pollutants c\u00f3 impact l\u1edbn",
        "   - Time features (hour, day_of_week) c\u0169ng quan tr\u1ecdng",
        "",
        "5. **24h Prediction**:",
        "   - Model c\u00f3 th\u1ec3 d\u1ef1 \u0111o\u00e1n AQI cho 24h ti\u1ebfp theo",
        "   - Predictions \u1ed5n \u0111\u1ecbnh v\u00e0 h\u1ee3p l\u00fd",
        "",
        "### Next Steps:",
        "",
        "1. **Model Improvements**:",
        "   - Implement LSTM v\u1edbi TensorFlow",
        "   - Try ensemble methods",
        "   - Hyperparameter tuning v\u1edbi Optuna/GridSearch",
        "",
        "2. **Data**:",
        "   - Thu th\u1eadp th\u00eam data t\u1eeb real-world sources",
        "   - Add more features (weather, traffic, events)",
        "   - Handle seasonal patterns",
        "",
        "3. **Deployment**:",
        "   - Build REST API v\u1edbi FastAPI/Flask",
        "   - Create web dashboard v\u1edbi Streamlit",
        "   - Deploy to cloud (AWS/GCP/Azure)",
        "",
        "4. **Monitoring**:",
        "   - Track model performance over time",
        "   - Implement retraining pipeline",
        "   - Add data drift detection",
        "",
        "---",
        "",
        "### \ud83c\udfaf Thank you for using this notebook!",
        "",
        "For more information, visit: [GitHub Repository](https://github.com/nghiata-uit/aqi-prediction)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}